name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  DOTNET_VERSION: '8.0.x'
  NODE_VERSION: '20.x'
  POSTGRES_VERSION: '16'

jobs:
  # Backend build and test
  backend:
    name: Backend Build & Test
    runs-on: [self-hosted, linux]

    permissions:
      checks: write
      contents: read

    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: koinon
          POSTGRES_PASSWORD: koinon_test
          POSTGRES_DB: koinon_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 25432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 26379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ env.DOTNET_VERSION }}
        global-json-file: global.json

    - name: Restore dependencies
      run: dotnet restore

    - name: Check code formatting
      run: dotnet format --verify-no-changes --verbosity diagnostic

    - name: Build solution
      run: dotnet build --no-restore --configuration Release

    - name: Run unit tests
      run: dotnet test --no-build --configuration Release --verbosity normal --logger "trx;LogFileName=test-results.trx"
      env:
        ConnectionStrings__KoinonDb: "Host=localhost;Port=25432;Database=koinon_test;Username=koinon;Password=koinon_test"
        ConnectionStrings__Redis: "localhost:26379"

    - name: Publish test results
      uses: dorny/test-reporter@v1
      if: always()
      with:
        name: Backend Tests
        path: '**/test-results.trx'
        reporter: dotnet-trx

    - name: Upload coverage reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: backend-coverage
        path: '**/coverage.cobertura.xml'

  # Frontend build and test
  frontend:
    name: Frontend Build & Test
    runs-on: [self-hosted, linux]

    defaults:
      run:
        working-directory: src/web

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: src/web/package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Run linter
      run: npm run lint

    - name: Run type checking
      run: npm run typecheck

    - name: Run tests
      run: npm test -- --coverage

    - name: Build production bundle
      run: npm run build

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: frontend-build
        path: src/web/dist

    - name: Upload coverage reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: frontend-coverage
        path: src/web/coverage

  # Migration safety check
  migration-check:
    name: Migration Safety Check
    runs-on: [self-hosted, linux]
    if: github.event_name == 'pull_request'

    permissions:
      checks: write
      contents: read

    services:
      postgres:
        image: postgis/postgis:16-3.5-alpine
        env:
          POSTGRES_USER: koinon
          POSTGRES_PASSWORD: koinon_test
          POSTGRES_DB: koinon_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 25433:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ env.DOTNET_VERSION }}
        global-json-file: global.json

    - name: Restore dependencies
      run: dotnet restore

    - name: Install local EF Core tools
      run: dotnet tool restore

    - name: Check for new migrations
      id: check-migrations
      run: |
        set -e

        MIGRATIONS_DIR="src/Koinon.Infrastructure/Migrations"

        if [ ! -d "$MIGRATIONS_DIR" ]; then
          echo "migrations_found=false" >> $GITHUB_OUTPUT
          echo "⚠️ Migrations directory not found"
          exit 0
        fi

        # Find actual migration files (exclude Designer.cs and ModelSnapshot.cs)
        # Compare against origin/main to find new migrations
        if git diff --name-only origin/main...HEAD -- "$MIGRATIONS_DIR/*.cs" | \
           grep -E "Migrations/[0-9]{14}_.*\.cs$" | \
           grep -v "\.Designer\.cs$" | \
           grep -v "ModelSnapshot\.cs$" > /tmp/new_migrations.txt; then

          if [ -s /tmp/new_migrations.txt ]; then
            echo "migrations_found=true" >> $GITHUB_OUTPUT
            echo "Found new migrations:"
            cat /tmp/new_migrations.txt
          else
            echo "migrations_found=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "migrations_found=false" >> $GITHUB_OUTPUT
        fi

    - name: Create migration database
      if: steps.check-migrations.outputs.migrations_found == 'true'
      run: |
        # Database koinon_test already created by service, no need to create
        echo "Using existing koinon_test database for migration validation"
    - name: Validate migrations can apply
      if: steps.check-migrations.outputs.migrations_found == 'true'
      run: |
        set -e

        echo "Restoring Infrastructure project..."
        dotnet restore src/Koinon.Infrastructure/Koinon.Infrastructure.csproj

        echo "Validating migrations can apply to database..."
        dotnet ef database update \
          --project src/Koinon.Infrastructure \
          --startup-project src/Koinon.Api \
          --verbose

        echo "✅ All migrations validated successfully"

      env:
        ConnectionStrings__KoinonDb: "Host=localhost;Port=25433;Database=koinon_test;Username=koinon;Password=koinon_test"
        Jwt__Secret: "ci-test-jwt-secret-key-minimum-32-characters-long"
        Jwt__Issuer: "koinon-ci-test"
        Jwt__Audience: "koinon-ci-test"

    - name: Check for destructive changes
      if: steps.check-migrations.outputs.migrations_found == 'true'
      run: |
        set -e

        MIGRATIONS_DIR="src/Koinon.Infrastructure/Migrations"
        TEMP_FILE="/tmp/destructive_check.txt"
        UP_METHODS_FILE="/tmp/up_methods.txt"

        echo "Checking for destructive database changes in Up() methods..."

        # List of destructive EF Core migration methods
        # Note: RenameIndex is excluded as it's a metadata-only operation (no data loss)
        DESTRUCTIVE_PATTERNS=(
          "DropTable"
          "DropColumn"
          "DropIndex"
          "DropConstraint"
          "DropForeignKey"
          "DropPrimaryKey"
          "DropUnique"
          "RenameTable"
          "RenameColumn"
        )

        DESTRUCTIVE_FOUND=false

        # Get list of new migration files
        NEW_MIGRATIONS=$(git diff --name-only origin/main...HEAD -- "$MIGRATIONS_DIR/*.cs" | \
          grep -E "Migrations/[0-9]{14}_.*\.cs$" | \
          grep -v "\.Designer\.cs$" | \
          grep -v "ModelSnapshot\.cs$" || true)

        if [ -z "$NEW_MIGRATIONS" ]; then
          echo "No new migration files to check"
          exit 0
        fi

        # Extract only Up() method content from each new migration
        # Down() methods contain legitimate rollback code (drops) - we ignore those
        > "$UP_METHODS_FILE"
        for migration in $NEW_MIGRATIONS; do
          if [ -f "$migration" ]; then
            echo "Checking: $migration"
            # Extract content between 'protected override void Up(' and 'protected override void Down('
            # This ensures we only check the Up() method, not the Down() rollback method
            awk '/protected override void Up\(/,/protected override void Down\(/' "$migration" | \
              head -n -1 >> "$UP_METHODS_FILE"
          fi
        done

        # Check Up() method content for destructive operations
        for pattern in "${DESTRUCTIVE_PATTERNS[@]}"; do
          if grep -n "migrationBuilder\.$pattern" "$UP_METHODS_FILE" > "$TEMP_FILE" 2>/dev/null; then
            if [ -s "$TEMP_FILE" ]; then
              echo ""
              echo "⚠️ WARNING: Potentially destructive operation detected in Up(): $pattern"
              echo "Location:"
              cat "$TEMP_FILE"
              echo ""
              DESTRUCTIVE_FOUND=true
            fi
          fi
        done

        if [ "$DESTRUCTIVE_FOUND" = true ]; then
          echo "❌ DESTRUCTIVE MIGRATION DETECTED"
          echo ""
          echo "This migration's Up() method contains operations that may result in data loss:"
          echo "- DropTable: Entire table and data removed"
          echo "- DropColumn: Column and all data removed"
          echo "- DropIndex: Performance impact"
          echo "- Other drop/rename operations: May cause service disruption"
          echo ""
          echo "REQUIRED: Please address one of the following:"
          echo "1. Refactor migration to preserve data (e.g., archive instead of drop)"
          echo "2. Add comment in migration explaining why data loss is acceptable"
          echo "3. Update this job's DESTRUCTIVE_PATTERNS to exclude safe patterns"
          echo ""
          echo "Note: Down() methods are NOT checked - rollback code legitimately uses drops"
          exit 1
        else
          echo "✅ No destructive changes detected in Up() methods"
          echo "   (Down() methods with rollback drops are expected and not flagged)"
        fi

        rm -f "$TEMP_FILE" "$UP_METHODS_FILE"

  # Integration smoke test
  # Runs job in a container so it shares network with service containers
  # See: https://docs.github.com/en/actions/using-containerized-services/about-service-containers
  integration:
    name: Integration Smoke Test
    runs-on: [self-hosted, linux]
    needs: [backend, frontend]

    # Run the job inside a container - this puts job + services on same Docker network
    # Using devcontainer image which has both .NET SDK and Node.js (required for GitHub Actions)
    container:
      image: mcr.microsoft.com/devcontainers/dotnet:8.0

    # Service containers - accessible by service name as hostname
    services:
      postgres:
        image: postgis/postgis:16-3.5-alpine
        env:
          POSTGRES_USER: koinon
          POSTGRES_PASSWORD: koinon
          POSTGRES_DB: koinon
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Restore and build API
      run: |
        dotnet restore
        dotnet build --no-restore --configuration Release

    - name: Apply database migrations
      run: |
        echo "Applying EF Core migrations..."
        dotnet tool restore
        dotnet ef database update \
          --project src/Koinon.Infrastructure \
          --startup-project src/Koinon.Api \
          --configuration Release
      env:
        ASPNETCORE_ENVIRONMENT: "Production"
        ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=koinon;Username=koinon;Password=koinon"
        Jwt__Secret: "ci-integration-test-jwt-key-minimum-32-chars-long-for-security"
        Jwt__Issuer: "koinon-ci-integration"
        Jwt__Audience: "koinon-ci-integration"

    - name: Start API in background
      run: |
        dotnet run --project src/Koinon.Api --no-build --configuration Release &
        echo $! > /tmp/api.pid
        echo "API started with PID $(cat /tmp/api.pid)"
        sleep 5
      env:
        ASPNETCORE_URLS: "http://0.0.0.0:5000"
        ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=koinon;Username=koinon;Password=koinon"
        ConnectionStrings__Redis: "redis:6379"
        Jwt__Secret: "ci-integration-test-jwt-key-minimum-32-chars-long-for-security"
        Jwt__Issuer: "koinon-ci-integration"
        Jwt__Audience: "koinon-ci-integration"

    - name: Wait for API to be ready
      run: |
        echo "Waiting for API to respond on http://localhost:5000/health..."
        apt-get update && apt-get install -y curl > /dev/null 2>&1 || true
        timeout 120 bash -c 'until curl -sf http://localhost:5000/health > /dev/null 2>&1; do
          echo "Waiting for API... (checking health endpoint)"
          sleep 3
        done'
        echo "API is ready!"

    - name: Check API health endpoint
      run: |
        echo "Fetching health check status..."
        HEALTH_RESPONSE=$(curl -s http://localhost:5000/health)
        echo "Health response: $HEALTH_RESPONSE"

        HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:5000/health)
        echo "HTTP Status: $HTTP_STATUS"

        if [ "$HTTP_STATUS" != "200" ]; then
          echo "❌ Health check failed with status $HTTP_STATUS"
          exit 1
        fi

        echo "✅ API health check passed"

    - name: Check database connectivity
      run: |
        apt-get install -y postgresql-client > /dev/null 2>&1 || true
        PGPASSWORD=koinon psql -h postgres -U koinon -d koinon -c "SELECT 1"

    - name: Cleanup
      if: always()
      run: |
        if [ -f /tmp/api.pid ]; then
          kill $(cat /tmp/api.pid) 2>/dev/null || true
        fi

  # Work unit validation
  work-unit-validation:
    name: Work Unit Validation
    runs-on: [self-hosted, linux]
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Check work-units.json is updated
      run: |
        if [ -f .claude/work-units.json ]; then
          echo "✅ Work units tracker exists"
          cat .claude/work-units.json
        else
          echo "⚠️ Work units tracker not found - creating empty tracker"
          mkdir -p .claude
          echo '{"completed":[],"in_progress":null,"blocked":[]}' > .claude/work-units.json
        fi

    - name: Validate JSON format
      run: |
        if [ -f .claude/work-units.json ]; then
          python3 -m json.tool .claude/work-units.json > /dev/null
          echo "✅ work-units.json is valid JSON"
        fi

  # Summary job
  ci-success:
    name: CI Success
    runs-on: [self-hosted, linux]
    needs: [backend, frontend, migration-check, integration, work-unit-validation]
    if: always()
    steps:
    - name: Check all jobs
      run: |
        if [[ "${{ needs.backend.result }}" == "success" ]] && \
           [[ "${{ needs.frontend.result }}" == "success" ]] && \
           [[ "${{ needs.migration-check.result }}" == "success" || "${{ needs.migration-check.result }}" == "skipped" ]] && \
           [[ "${{ needs.integration.result }}" == "success" ]] && \
           [[ "${{ needs.work-unit-validation.result }}" == "success" || "${{ needs.work-unit-validation.result }}" == "skipped" ]]; then
          echo "✅ All CI checks passed"
          exit 0
        else
          echo "❌ One or more CI checks failed"
          exit 1
        fi
